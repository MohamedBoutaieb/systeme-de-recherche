{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PyPDF2\n",
    "import docx\n",
    "from datetime import datetime\n",
    "import getpass  # Module for getting the username\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import shutil\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation de datasets de références qui servira comme vocabultaire pour chaque catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "def read_csv(file_path):\n",
    "    words = []\n",
    "    with open(file_path, 'r', newline='') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            word =lemmatizer.lemmatize(row['Word'].lower())\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "sports_words = read_csv('datasets/sports.csv')\n",
    "cooking_words = read_csv('datasets/cooking.csv')\n",
    "travel_words = read_csv('datasets/travel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## enrichissement des datasets par le vocabulaire de nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "syns = wordnet.synsets(\"sports\")\n",
    "sports = []\n",
    "for s in syns:\n",
    "    for l in s.lemmas():\n",
    "        sports.append(stemmer.stem(l.name()))\n",
    "sports_dataset = set(sports)\n",
    "sports_dataset.update(set(sports_words))\n",
    "\n",
    "syns = wordnet.synsets(\"cooking\")\n",
    "cooking = []\n",
    "for s in syns:\n",
    "    for l in s.lemmas():\n",
    "        cooking.append(stemmer.stem(l.name()))\n",
    "cooking_dataset = set(cooking)\n",
    "cooking_dataset.update(set(cooking_words))\n",
    "syns = wordnet.synsets(\"travel\")\n",
    "travel = []\n",
    "for s in syns:\n",
    "    for l in s.lemmas():\n",
    "        travel.append(stemmer.stem(l.name()))\n",
    "travel_dataset = set(travel)\n",
    "travel_dataset.update(set(travel_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Manager qui permet de lire, classifier les fichier ainsi que les indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['titl', '', '', 'evolut', 'game', '', 'pixel', 'virtual', 'realiti', '', 'introduct', '', 'realm', 'entertain', '', 'industri', 'experienc', 'rapid', 'transform', 'growth', 'game', 'industri', '', 'humbl', 'begin', 'pixel', 'charact', 'arcad', 'screen', 'immers', 'world', 'virtual', 'realiti', '', 'game', 'evolv', 'multibilliondollar', 'global', 'phenomenon', '', 'articl', 'delv', 'fascin', 'journey', 'game', '', 'trace', 'evolut', 'decad', '', 'birth', 'game', '', 'stori', 'begin', 'earli', '1970', 'birth', 'arcad', 'game', '', 'game', 'like', 'pong', 'space', 'invad', 'introduc', 'world', 'addict', 'allur', 'electron', 'entertain', '', 'pixel', 'graphic', 'simpl', 'gameplay', 'earli', 'titl', 'set', 'foundat', 'come', '', 'rise', 'consol', '', 'technolog', 'advanc', '', 'game', 'experi', '', '1980', 'wit', 'rise', 'home', 'game', 'consol', '', 'icon', 'nintendo', 'entertain', 'system', '', 'ne', '', 'lead', 'way', '', 'suddenli', '', 'game', 'nt', 'confin', 'arcad', '', 'becam', 'commun', 'experi', 'within', 'live', 'room', '', 'gamer', 'could', 'explor', 'vast', 'new', 'world', 'game', 'like', 'super', 'mario', 'bro', 'legend', 'zelda', '', 'pc', 'game', 'renaiss', '', '1990', 'saw', 'emerg', 'person', 'comput', 'power', 'game', 'platform', '', 'titl', 'like', 'doom', 'quak', 'brought', 'firstperson', 'shooter', 'forefront', '', 'showcas', 'potenti', 'pc', 'game', '', 'advent', 'cdrom', 'allow', 'expans', 'game', 'cinemat', 'storytel', '', 'elev', 'medium', '', 'internet', 'revolut', '', 'turn', 'millennium', 'brought', 'paradigm', 'shift', 'rise', 'onlin', 'game', '', 'highspe', 'internet', 'connect', 'enabl', 'player', 'connect', 'global', '', 'massiv', 'multiplay', 'onlin', 'roleplay', 'game', '', 'mmorpg', '', 'like', 'world', 'warcraft', 'captiv', 'million', '', 'creat', 'virtual', 'societi', 'economi', '', 'mobil', 'game', 'take', 'center', 'stage', '', 'advent', 'smartphon', '', 'game', 'becam', 'even', 'access', '', 'mobil', 'game', 'introduc', 'new', 'demograph', 'interact', 'entertain', '', 'simpl', 'yet', 'addict', 'game', 'like', 'angri', 'bird', 'candi', 'crush', 'saga', 'becam', 'cultur', 'phenomena', '', 'demonstr', 'potenti', 'game', 'handheld', 'devic', '', 'era', 'highfidel', 'graphic', 'virtual', 'realiti', '', 'recent', 'year', '', 'advanc', 'hardwar', 'allow', 'unpreced', 'level', 'realism', 'game', '', 'highfidel', 'graphic', '', '4k', 'resolut', '', 'ray', 'trace', 'elev', 'visual', 'experi', '', 'meanwhil', '', 'virtual', 'realiti', '', 'vr', '', 'open', 'entir', 'new', 'dimens', '', 'immers', 'player', 'lifelik', 'environ', 'provid', 'tast', 'futur', 'interact', 'entertain', '', 'futur', 'game', '', 'technolog', 'continu', 'advanc', '', 'futur', 'game', 'hold', 'even', 'excit', 'possibl', '', 'cloud', 'game', 'servic', '', 'augment', 'realiti', '', 'artifici', 'intellig', 'pois', 'shape', 'next', 'chapter', 'game', '', 'everexpand', 'audienc', 'industri', 'show', 'sign', 'slow', '', 'game', 'set', 'continu', 'remark', 'journey', 'unchart', 'territori', '', 'conclus', '', 'simpl', 'pleasur', 'pong', 'mindbend', 'experi', 'virtual', 'realiti', '', 'game', 'come', 'long', 'way', '', 'evolut', 'game', 'reflect', 'technolog', 'progress', 'also', 'creativ', 'passion', 'countless', 'develop', 'gamer', 'worldwid', '', 'look', 'ahead', '', 'certainti', 'world', 'game', 'continu', 'surpris', 'captiv', 'us', 'innov', 'push', 'boundari', 'possibl', 'realm', 'interact', 'entertain', '']\n",
      "mohamedboutaieb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class FileManager:\n",
    "    def __init__(self):\n",
    "        self.inverse_index = {}\n",
    "        self.time_index = {}\n",
    "        self.owner_index = {}\n",
    "        self.stem = PorterStemmer()\n",
    "\n",
    "    def upload_file(self, file_path):\n",
    "        full_text = \"\"\n",
    "        if file_path.endswith(\".pdf\"):\n",
    "            with open(file_path, \"rb\") as file:\n",
    "                if file_path.endswith(\".pdf\"):\n",
    "                    pdfReader = PyPDF2.PdfFileReader(file)\n",
    "                    for pageNum in range(pdfReader.numPages):\n",
    "                        pageObj = pdfReader.getPage(pageNum)\n",
    "                        text = pageObj.extractText()\n",
    "                        full_text += text\n",
    "        elif file_path.endswith(\".txt\"):\n",
    "            with open(file_path, \"r\",encoding=\"utf-8\") as file:\n",
    "                full_text = file.read()\n",
    "        elif file_path.endswith(\".docx\"):\n",
    "            document = docx.Document(file_path)\n",
    "            for paragraph in document.paragraphs:\n",
    "                full_text += paragraph.text\n",
    "        return full_text\n",
    "\n",
    "    def index_file_by_date(self, file_path):\n",
    "        # Get the creation time of the file\n",
    "        timestamp = os.path.getctime(file_path)\n",
    "        file_time = datetime.fromtimestamp(timestamp).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Indexing the file by date and time\n",
    "        if file_time not in self.time_index:\n",
    "            self.time_index[file_time] = set()\n",
    "        self.time_index[file_time].add(file_path)\n",
    "\n",
    "    def index_file_by_owner(self, file_path):\n",
    "        # Get the owner of the file\n",
    "        uid = os.stat(file_path).st_uid\n",
    "        # Get the owner's username\n",
    "        owner = getpass.getuser()\n",
    "        # Indexing the file by owner\n",
    "        if owner not in self.owner_index:\n",
    "            self.owner_index[owner] = set()\n",
    "        self.owner_index[owner].add(file_path)\n",
    "        return owner\n",
    "\n",
    "    def inverse_index_files(self):\n",
    "        # read the files in the docs folder\n",
    "        for root, dirs, files in os.walk(\"docs\"):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                text = self.upload_file(file_path)\n",
    "                tokens = self.tokenize(text)\n",
    "                # inverse index the file\n",
    "                for token in tokens:\n",
    "                    if token not in self.inverse_index:\n",
    "                        self.inverse_index[token] = set()\n",
    "                    self.inverse_index[token].add(file_path.split(\"\\\\\")[-1])\n",
    "        return self.inverse_index\n",
    "\n",
    "    def search_keyword(self, keyword):\n",
    "        if keyword.lower() in self.inverse_index:\n",
    "            return self.inverse_index[keyword.lower()]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        # Load the list of stop words\n",
    "        stopword = stopwords.words(\"english\")\n",
    "        # Tokenize the text\n",
    "        tokens = word_tokenize(text)\n",
    "        # Convert the tokens into lower case\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        # Remove the stop words and empty spaces\n",
    "        tokens = [token for token in tokens if token not in stopword and token != \"\"]\n",
    "\n",
    "        # Remove the punctuation\n",
    "        tokens = [re.sub(r\"[^a-zA-Z0-9]\", \"\", token) for token in tokens]\n",
    "        # stem the tokens\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "        return tokens\n",
    "\n",
    "    def word_occ_positions(self, tokens):\n",
    "        word_position = {}\n",
    "        for index, word in enumerate(tokens):\n",
    "            if word not in word_position:\n",
    "                word_position[word] = []\n",
    "            word_position[word].append(index)\n",
    "        return word_position\n",
    "\n",
    "    def search_keyword_association(self, keywords):\n",
    "        # Get the files that contain the keywords\n",
    "        files = []\n",
    "        for keyword in keywords:\n",
    "            key = self.search_keyword(stemmer.stem(keyword))\n",
    "            for k in key:\n",
    "                files.append(k)\n",
    "\n",
    "        # Get the intersection of the files\n",
    "        print(files)\n",
    "        files = set(files)\n",
    "        return files\n",
    "\n",
    "    def classify_file(self, file_path):\n",
    "        uploaded_file = self.upload_file(file_path)\n",
    "        tokens = self.tokenize(uploaded_file)\n",
    "        word_occ_positions = self.word_occ_positions(tokens)\n",
    "        max_section = self.evaluate_text(word_occ_positions)\n",
    "        # if (max_section ==''):\n",
    "        #     rand = ['sports','cooking','travel']\n",
    "        #     max_section = rand[random.randint(0,2)]\n",
    "        file = os.path.basename(file_path)\n",
    "        shutil.copy2(file_path, f\"docs/{max_section}/{file.split('.')[1]}/{file}\")\n",
    "    \n",
    "    def evaluate_text(self,word_occ_positions):\n",
    "        scores = {}\n",
    "        sections = {\n",
    "            \"sports\": sports_dataset,\n",
    "            \"cooking\": cooking_dataset,\n",
    "            \"travel\": travel_dataset,\n",
    "        }\n",
    "        max_score = 0\n",
    "        max_section = ''\n",
    "        for section in sections:\n",
    "            scores[section] = 0\n",
    "            for keyword in sections[section]:\n",
    "                if keyword in word_occ_positions:\n",
    "                    scores[section] += len(word_occ_positions[keyword])\n",
    "    \n",
    "            if scores[section] > max_score:\n",
    "                max_score = scores[section]\n",
    "                max_section = section\n",
    "        return max_section\n",
    "# Exemple d'utilisation\n",
    "file_manager = FileManager()\n",
    "\n",
    "test = file_manager.upload_file(\"gaming.txt\")\n",
    "index = file_manager.index_file_by_date(\"test.txt\")\n",
    "owner = file_manager.index_file_by_owner(\"file3.txt\")\n",
    "\n",
    "tokens = file_manager.tokenize(test)\n",
    "\n",
    "print(tokens)\n",
    "print(owner)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cette fonction determine la categorie du fichier et le classifie dans l'arborecence des dossiers\n",
    "file_manager.classify_file(\"file2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation du système de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5777777777777777\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_sports</th>\n",
       "      <th>pred_cooking</th>\n",
       "      <th>pred_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cooking</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred_sports  pred_cooking  pred_travel\n",
       "sports            11             0            1\n",
       "cooking            0             7            0\n",
       "travel             1             3            8"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def read_texts_from_csv(csv_file):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            text = row['Text']\n",
    "            label = row['Category'].lower()\n",
    "            labels.append(label)\n",
    "            texts.append(text)\n",
    "    return texts, labels\n",
    "\n",
    "# Replace 'your_dataset.csv' with the actual filename of your CSV dataset\n",
    "csv_file_path = 'dataset.csv'\n",
    "\n",
    "# Read texts from the CSV dataset\n",
    "texts_without_labels,labels = read_texts_from_csv(csv_file_path)\n",
    "\n",
    "predictions = []\n",
    "for text in texts_without_labels:\n",
    "    tokens = file_manager.tokenize(text)\n",
    "    # print(tokens)\n",
    "    word_occ_positions = file_manager.word_occ_positions(tokens)\n",
    "    max_section = file_manager.evaluate_text(word_occ_positions)\n",
    "    predictions.append(max_section)\n",
    "\n",
    "score = 0\n",
    "# Step 6: Evaluate the accuracy of the model\n",
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == predictions[i]:\n",
    "        score+=1\n",
    "score /= len(labels) \n",
    "print(score)\n",
    "# draw confusion matrix \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "array = confusion_matrix(labels, predictions, labels=['sports', 'cooking', 'travel'])\n",
    "df_cm = pd.DataFrame(array, index = ['sports', 'cooking', 'travel'],\n",
    "                  columns = ['pred_sports', 'pred_cooking', 'pred_travel'])\n",
    "\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche de Fichier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'titl': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " '': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'modern_travel.docx',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'art': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'joy': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'cook': {'file3_554.txt'},\n",
       " 'culinari': {'file3_554.txt'},\n",
       " 'journey': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'flavor': {'file3_554.txt', 'voyage.txt'},\n",
       " 'creation': {'file3_554.txt'},\n",
       " 'introduct': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'often': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'regard': {'file3_554.txt'},\n",
       " 'scienc': {'file3_554.txt'},\n",
       " 'univers': {'file3_554.txt'},\n",
       " 'languag': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'transcend': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'cultur': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'boundari': {'file3_554.txt'},\n",
       " 'sizzl': {'file3_554.txt'},\n",
       " 'sound': {'file3_554.txt'},\n",
       " 'saut': {'file3_554.txt'},\n",
       " 'pan': {'file3_554.txt'},\n",
       " 'aromat': {'file3_554.txt'},\n",
       " 'symphoni': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'herb': {'file3_554.txt'},\n",
       " 'spice': {'file3_554.txt'},\n",
       " 'kitchen': {'file3_554.txt'},\n",
       " 'canva': {'file3_554.txt', 'voyage.txt'},\n",
       " 'creativ': {'file3_554.txt'},\n",
       " 'meet': {'file3_554.txt'},\n",
       " 'nourish': {'file3_554.txt'},\n",
       " 'articl': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'explor': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'enchant': {'file3_554.txt'},\n",
       " 'world': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'alchemi': {'file3_554.txt'},\n",
       " 'ingredi': {'file3_554.txt'},\n",
       " 'transform': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'delight': {'file3_554.txt'},\n",
       " 'palett': {'file3_554.txt'},\n",
       " 'express': {'file3_554.txt'},\n",
       " 'form': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'color': {'file3_554.txt'},\n",
       " 'fresh': {'file3_554.txt'},\n",
       " 'veget': {'file3_554.txt'},\n",
       " 'succul': {'file3_554.txt'},\n",
       " 'meat': {'file3_554.txt'},\n",
       " 'possibl': {'file3_554.txt'},\n",
       " 'endless': {'file3_554.txt'},\n",
       " 'chef': {'file3_554.txt'},\n",
       " 'profession': {'file3_554.txt', 'tigerwood__55.txt'},\n",
       " 'amateur': {'file3_554.txt'},\n",
       " 'experi': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'textur': {'file3_554.txt'},\n",
       " 'aroma': {'file3_554.txt'},\n",
       " 'creat': {'file3_554.txt'},\n",
       " 'dish': {'file3_554.txt'},\n",
       " 'tantal': {'file3_554.txt'},\n",
       " 'tast': {'file3_554.txt', 'voyage.txt'},\n",
       " 'bud': {'file3_554.txt'},\n",
       " 'evok': {'file3_554.txt'},\n",
       " 'emot': {'file3_554.txt'},\n",
       " 'ritual': {'file3_554.txt'},\n",
       " 'prepar': {'file3_554.txt'},\n",
       " 'begin': {'file3_554.txt', 'tigerwood__55.txt'},\n",
       " 'meticul': {'file3_554.txt'},\n",
       " 'chop': {'file3_554.txt'},\n",
       " 'dice': {'file3_554.txt'},\n",
       " 'minc': {'file3_554.txt'},\n",
       " 'becom': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'rhythmic': {'file3_554.txt'},\n",
       " 'danc': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'sanctuari': {'file3_554.txt'},\n",
       " 'tactil': {'file3_554.txt'},\n",
       " 'handl': {'file3_554.txt'},\n",
       " 'knife': {'file3_554.txt'},\n",
       " 'cut': {'file3_554.txt'},\n",
       " 'board': {'file3_554.txt', 'tigerwood__55.txt'},\n",
       " 'vibrant': {'file3_554.txt', 'voyage.txt'},\n",
       " 'produc': {'file3_554.txt'},\n",
       " 'contribut': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'sensori': {'file3_554.txt'},\n",
       " 'pleasur': {'file3_554.txt'},\n",
       " 'techniqu': {'file3_554.txt'},\n",
       " 'blend': {'file3_554.txt'},\n",
       " 'whether': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 's': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'precis': {'file3_554.txt'},\n",
       " 'sou': {'file3_554.txt'},\n",
       " 'vide': {'file3_554.txt'},\n",
       " 'intens': {'file3_554.txt'},\n",
       " 'heat': {'file3_554.txt'},\n",
       " 'grill': {'file3_554.txt'},\n",
       " 'slow': {'file3_554.txt'},\n",
       " 'simmer': {'file3_554.txt'},\n",
       " 'stew': {'file3_554.txt'},\n",
       " 'method': {'file3_554.txt'},\n",
       " 'impart': {'file3_554.txt'},\n",
       " 'uniqu': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'charact': {'file3_554.txt'},\n",
       " 'final': {'file3_554.txt'},\n",
       " 'enhanc': {'file3_554.txt'},\n",
       " 'also': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'showcas': {'file3_554.txt'},\n",
       " 'craftsmanship': {'file3_554.txt'},\n",
       " 'power': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyager1.txt'},\n",
       " 'season': {'file3_554.txt'},\n",
       " 'magic': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'touch': {'file3_554.txt'},\n",
       " 'elev': {'file3_554.txt'},\n",
       " 'ordinari': {'file3_554.txt'},\n",
       " 'extraordinari': {'file3_554.txt'},\n",
       " 'salt': {'file3_554.txt'},\n",
       " 'pepper': {'file3_554.txt'},\n",
       " 'alchemist': {'file3_554.txt'},\n",
       " 'turn': {'file3_554.txt'},\n",
       " 'collect': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'harmoni': {'file3_554.txt'},\n",
       " 'composit': {'file3_554.txt'},\n",
       " 'balanc': {'file3_554.txt'},\n",
       " 'flavorssweet': {'file3_554.txt'},\n",
       " 'salti': {'file3_554.txt'},\n",
       " 'sour': {'file3_554.txt'},\n",
       " 'bitter': {'file3_554.txt'},\n",
       " 'umamicr': {'file3_554.txt'},\n",
       " 'linger': {'file3_554.txt'},\n",
       " 'palat': {'file3_554.txt'},\n",
       " 'tradit': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'deepli': {'file3_554.txt'},\n",
       " 'root': {'file3_554.txt'},\n",
       " 'reflect': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'divers': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'cuisin': {'file3_554.txt'},\n",
       " 'region': {'file3_554.txt'},\n",
       " 'boast': {'file3_554.txt'},\n",
       " 'ident': {'file3_554.txt'},\n",
       " 'timehonor': {'file3_554.txt'},\n",
       " 'recip': {'file3_554.txt'},\n",
       " 'pass': {'file3_554.txt'},\n",
       " 'gener': {'file3_554.txt', 'voyage.txt'},\n",
       " 'appreci': {'file3_554.txt'},\n",
       " 'differ': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'allow': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'richer': {'file3_554.txt'},\n",
       " 'understand': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyager1.txt'},\n",
       " 'peopl': {'file3_554.txt'},\n",
       " 'share': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'bodi': {'file3_554.txt'},\n",
       " 'foster': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'connect': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'act': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'meal': {'file3_554.txt'},\n",
       " 'mere': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'susten': {'file3_554.txt'},\n",
       " 'commun': {'file3_554.txt', 'voyage.txt'},\n",
       " 'bring': {'file3_554.txt'},\n",
       " 'togeth': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'famili': {'file3_554.txt'},\n",
       " 'dinner': {'file3_554.txt'},\n",
       " 'festiv': {'file3_554.txt'},\n",
       " 'celebr': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'casual': {'file3_554.txt'},\n",
       " 'gather': {'file3_554.txt'},\n",
       " 'friend': {'file3_554.txt'},\n",
       " 'food': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'last': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyager1.txt'},\n",
       " 'memori': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'continu': {'file3_554.txt'},\n",
       " 'beauti': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'modern_travel.docx',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'lie': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'infinit': {'file3_554.txt'},\n",
       " 'discoveri': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'learn': {'file3_554.txt'},\n",
       " 'adapt': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'master': {'file3_554.txt'},\n",
       " 'classic': {'file3_554.txt'},\n",
       " 'innov': {'file3_554.txt'},\n",
       " 'everi': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyager1.txt'},\n",
       " 'embark': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'person': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyager1.txt'},\n",
       " 'odyssey': {'file3_554.txt'},\n",
       " 'laboratori': {'file3_554.txt'},\n",
       " 'experiment': {'file3_554.txt'},\n",
       " 'mistak': {'file3_554.txt'},\n",
       " 'lesson': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'triumph': {'file3_554.txt'},\n",
       " 'conclus': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'heart': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'emerg': {'file3_554.txt', 'modern_travel.docx', 'voyage.txt'},\n",
       " 'testament': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'oneself': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'other': {'file3_554.txt', 'voyage.txt'},\n",
       " 're': {'file3_554.txt'},\n",
       " 'novic': {'file3_554.txt'},\n",
       " 'beckon': {'file3_554.txt'},\n",
       " 'realm': {'file3_554.txt'},\n",
       " 'invit': {'file2.txt', 'file3_554.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'adventur': {'file2.txt',\n",
       "  'file3_554.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'nassau': {'tigerwood__55.txt'},\n",
       " 'bahama': {'tigerwood__55.txt'},\n",
       " 'decad': {'tigerwood__55.txt'},\n",
       " 'tiger': {'tigerwood__55.txt'},\n",
       " 'wood': {'tigerwood__55.txt'},\n",
       " 'career': {'tigerwood__55.txt'},\n",
       " 'seri': {'tigerwood__55.txt'},\n",
       " 'stop': {'tigerwood__55.txt'},\n",
       " 'start': {'tigerwood__55.txt'},\n",
       " 'golf': {'tigerwood__55.txt'},\n",
       " 'grasp': {'tigerwood__55.txt'},\n",
       " 'comeback': {'tigerwood__55.txt'},\n",
       " 'goe': {'file2.txt', 'tigerwood__55.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'away': {'tigerwood__55.txt'},\n",
       " 'promis': {'tigerwood__55.txt'},\n",
       " 'anoth': {'file2.txt', 'tigerwood__55.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'new': {'file2.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'brought': {'tigerwood__55.txt'},\n",
       " 'group': {'file2.txt', 'tigerwood__55.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'wait': {'file2.txt', 'tigerwood__55.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'patient': {'tigerwood__55.txt'},\n",
       " 'mercedesbenz': {'tigerwood__55.txt'},\n",
       " 'much': {'tigerwood__55.txt'},\n",
       " 'like': {'tigerwood__55.txt'},\n",
       " 'one': {'file2.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'ferri': {'tigerwood__55.txt'},\n",
       " 'key': {'tigerwood__55.txt'},\n",
       " 'partner': {'tigerwood__55.txt'},\n",
       " 'part': {'tigerwood__55.txt'},\n",
       " 'albani': {'tigerwood__55.txt'},\n",
       " 'cours': {'tigerwood__55.txt'},\n",
       " 'appear': {'tigerwood__55.txt'},\n",
       " 'seemingli': {'tigerwood__55.txt'},\n",
       " 'thin': {'tigerwood__55.txt'},\n",
       " 'air': {'tigerwood__55.txt'},\n",
       " 'walk': {'file2.txt', 'tigerwood__55.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'around': {'tigerwood__55.txt'},\n",
       " 'corner': {'file2.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyager1.txt'},\n",
       " 'white': {'tigerwood__55.txt'},\n",
       " 'tent': {'tigerwood__55.txt'},\n",
       " 'alon': {'tigerwood__55.txt'},\n",
       " 'simpli': {'tigerwood__55.txt'},\n",
       " 'morn': {'tigerwood__55.txt'},\n",
       " 'stroll': {'tigerwood__55.txt'},\n",
       " 'said': {'tigerwood__55.txt'},\n",
       " 'hey': {'tigerwood__55.txt'},\n",
       " 'guy': {'tigerwood__55.txt'},\n",
       " 'media': {'tigerwood__55.txt', 'voyage.txt'},\n",
       " '1': {'tigerwood__55.txt'},\n",
       " 'player': {'tigerwood__55.txt'},\n",
       " 'field': {'tigerwood__55.txt'},\n",
       " 'rel': {'tigerwood__55.txt'},\n",
       " 'obscur': {'tigerwood__55.txt'},\n",
       " 'tournament': {'tigerwood__55.txt'},\n",
       " 'caribbean': {'tigerwood__55.txt'},\n",
       " '2023': {'tigerwood__55.txt'},\n",
       " 'pga': {'tigerwood__55.txt'},\n",
       " 'tour': {'tigerwood__55.txt'},\n",
       " 'champion': {'tigerwood__55.txt'},\n",
       " 'two': {'tigerwood__55.txt'},\n",
       " 'major': {'tigerwood__55.txt'},\n",
       " 'winner': {'tigerwood__55.txt'},\n",
       " 'rest': {'tigerwood__55.txt'},\n",
       " 'biggest': {'tigerwood__55.txt'},\n",
       " 'name': {'tigerwood__55.txt'},\n",
       " 'alway': {'tigerwood__55.txt'},\n",
       " 'attent': {'tigerwood__55.txt'},\n",
       " 'focus': {'tigerwood__55.txt'},\n",
       " 'instead': {'tigerwood__55.txt'},\n",
       " 'man': {'tigerwood__55.txt'},\n",
       " 'current': {'tigerwood__55.txt'},\n",
       " 'rank': {'tigerwood__55.txt'},\n",
       " '1328': {'tigerwood__55.txt'},\n",
       " 'first': {'tigerwood__55.txt'},\n",
       " 'sat': {'tigerwood__55.txt'},\n",
       " 'annual': {'tigerwood__55.txt'},\n",
       " 'press': {'tigerwood__55.txt'},\n",
       " 'confer': {'tigerwood__55.txt'},\n",
       " 'preview': {'tigerwood__55.txt'},\n",
       " 'hero': {'tigerwood__55.txt'},\n",
       " 'challeng': {'file2.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyager1.txt'},\n",
       " 'nocut': {'tigerwood__55.txt'},\n",
       " 'limitedfield': {'tigerwood__55.txt'},\n",
       " 'event': {'tigerwood__55.txt'},\n",
       " 'host': {'tigerwood__55.txt'},\n",
       " 'buddi': {'tigerwood__55.txt'},\n",
       " 'discuss': {'tigerwood__55.txt'},\n",
       " 'state': {'tigerwood__55.txt'},\n",
       " 'look': {'tigerwood__55.txt'},\n",
       " '15time': {'tigerwood__55.txt'},\n",
       " 'convers': {'file2.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyager1.txt'},\n",
       " 'unfold': {'tigerwood__55.txt'},\n",
       " 'realiti': {'tigerwood__55.txt', 'voyage.txt'},\n",
       " 'front': {'tigerwood__55.txt'},\n",
       " 'us': {'file2.txt', 'tigerwood__55.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'becam': {'tigerwood__55.txt'},\n",
       " 'clear': {'tigerwood__55.txt'},\n",
       " 'polici': {'tigerwood__55.txt'},\n",
       " 'member': {'tigerwood__55.txt'},\n",
       " 'cofound': {'tigerwood__55.txt'},\n",
       " 'leagu': {'tigerwood__55.txt'},\n",
       " 'investor': {'tigerwood__55.txt'},\n",
       " 'restaurateur': {'tigerwood__55.txt'},\n",
       " 'design': {'tigerwood__55.txt'},\n",
       " '47yearold': {'tigerwood__55.txt'},\n",
       " 'legend': {'tigerwood__55.txt'},\n",
       " 'transit': {'tigerwood__55.txt'},\n",
       " 'toward': {'file2.txt',\n",
       "  'tigerwood__55.txt',\n",
       "  'travel2299.txt',\n",
       "  'voyager1.txt'},\n",
       " 'authorit': {'tigerwood__55.txt'},\n",
       " 'senior': {'tigerwood__55.txt'},\n",
       " 'presenc': {'tigerwood__55.txt'},\n",
       " 'sport': {'tigerwood__55.txt'},\n",
       " 'crisi': {'tigerwood__55.txt'},\n",
       " 'say': {'tigerwood__55.txt'},\n",
       " 'quip': {'tigerwood__55.txt'},\n",
       " 'yet': {'tigerwood__55.txt'},\n",
       " 'got': {'tigerwood__55.txt'},\n",
       " 'coupl': {'tigerwood__55.txt'},\n",
       " 'year': {'tigerwood__55.txt'},\n",
       " 'golfer': {'tigerwood__55.txt'},\n",
       " 'plan': {'tigerwood__55.txt'},\n",
       " 'keep': {'tigerwood__55.txt'},\n",
       " 'play': {'tigerwood__55.txt', 'voyage.txt'},\n",
       " 'right': {'tigerwood__55.txt'},\n",
       " 'ankl': {'tigerwood__55.txt'},\n",
       " 'strong': {'tigerwood__55.txt'},\n",
       " 'enough': {'tigerwood__55.txt'},\n",
       " '18': {'tigerwood__55.txt'},\n",
       " 'hole': {'tigerwood__55.txt'},\n",
       " 'without': {'tigerwood__55.txt', 'voyage.txt'},\n",
       " 'pain': {'tigerwood__55.txt'},\n",
       " 'follow': {'tigerwood__55.txt'},\n",
       " 'postmast': {'tigerwood__55.txt'},\n",
       " 'subtalar': {'tigerwood__55.txt'},\n",
       " 'fusion': {'tigerwood__55.txt'},\n",
       " 'surgeri': {'tigerwood__55.txt'},\n",
       " 'even': {'tigerwood__55.txt'},\n",
       " 'hint': {'tigerwood__55.txt'},\n",
       " 'onceamonth': {'tigerwood__55.txt'},\n",
       " 'schedul': {'tigerwood__55.txt'},\n",
       " '2024': {'tigerwood__55.txt'},\n",
       " 'would': {'tigerwood__55.txt'},\n",
       " 'includ': {'tigerwood__55.txt'},\n",
       " 'four': {'tigerwood__55.txt'},\n",
       " 'littl': {'tigerwood__55.txt'},\n",
       " 'focu': {'tigerwood__55.txt'},\n",
       " 'tuesday': {'tigerwood__55.txt'},\n",
       " 'abil': {'tigerwood__55.txt'},\n",
       " 'futur': {'modern_travel.docx', 'tigerwood__55.txt', 'voyage.txt'},\n",
       " 'joke': {'tigerwood__55.txt'},\n",
       " 'curiou': {'tigerwood__55.txt'},\n",
       " 'go': {'tigerwood__55.txt'},\n",
       " 'happen': {'tigerwood__55.txt'},\n",
       " 'done': {'tigerwood__55.txt'},\n",
       " 'while': {'tigerwood__55.txt'},\n",
       " 'latest': {'tigerwood__55.txt'},\n",
       " 'secondari': {'tigerwood__55.txt'},\n",
       " 'storylin': {'tigerwood__55.txt'},\n",
       " 'men': {'tigerwood__55.txt'},\n",
       " 'politicianexecut': {'tigerwood__55.txt'},\n",
       " 'talk': {'tigerwood__55.txt'},\n",
       " 'confid': {'tigerwood__55.txt'},\n",
       " 'issu': {'tigerwood__55.txt'},\n",
       " 'answer': {'tigerwood__55.txt'},\n",
       " 'question': {'tigerwood__55.txt'},\n",
       " 'statu': {'tigerwood__55.txt'},\n",
       " 'public': {'tigerwood__55.txt'},\n",
       " 'invest': {'tigerwood__55.txt'},\n",
       " 'fund': {'tigerwood__55.txt'},\n",
       " 'saudi': {'tigerwood__55.txt'},\n",
       " 'arabia': {'tigerwood__55.txt'},\n",
       " 'negoti': {'tigerwood__55.txt'},\n",
       " 'convict': {'tigerwood__55.txt'},\n",
       " 'commission': {'tigerwood__55.txt'},\n",
       " 'jay': {'tigerwood__55.txt'},\n",
       " 'monahan': {'tigerwood__55.txt'},\n",
       " 'mayb': {'tigerwood__55.txt'},\n",
       " 'author': {'tigerwood__55.txt'},\n",
       " 'wield': {'tigerwood__55.txt'},\n",
       " 'three': {'tigerwood__55.txt'},\n",
       " 'time': {'modern_travel.docx', 'tigerwood__55.txt', 'voyage.txt'},\n",
       " 'make': {'file2.txt', 'tigerwood__55.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'deal': {'tigerwood__55.txt'},\n",
       " 'pif': {'tigerwood__55.txt'},\n",
       " 'input': {'tigerwood__55.txt'},\n",
       " 'sustain': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'paramount': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'consider': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'modern': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'travel': {'file2.txt',\n",
       "  'modern_travel.docx',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'consciou': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'strive': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'minim': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'environment': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'footprint': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'opt': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'ecofriendli': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'accommod': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'support': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'local': {'file2.txt',\n",
       "  'modern_travel.docx',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'initi': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'choos': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'transport': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'option': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'priorit': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'respons': {'file2.txt',\n",
       "  'modern_travel.docx',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'tourism': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'trend': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'commit': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'preserv': {'file2.txt',\n",
       "  'modern_travel.docx',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'destin': {'file2.txt',\n",
       "  'modern_travel.docx',\n",
       "  'travel2299.txt',\n",
       "  'voyage.txt',\n",
       "  'voyager1.txt'},\n",
       " 'generationsth': {'modern_travel.docx'},\n",
       " 'concept': {'modern_travel.docx', 'voyage.txt'},\n",
       " 'wanderlust': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'unleash': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'movement': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'place': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'expand': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'horizon': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'enrich': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'soul': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'broaden': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'perspect': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'allur': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'discov': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'landscap': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'immers': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'embrac': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'unknown': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'fuel': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'human': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'spirit': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'centuri': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'beyond': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'mile': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'map': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'vast': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'tapestri': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'bustl': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'market': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'marrakech': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'seren': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'patagonia': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'chapter': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'read': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'thrill': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'famou': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'landmark': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'hidden': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'gem': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'unchart': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'reveal': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'true': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'essenc': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'aspect': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'opportun': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'savor': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'street': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'bangkok': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'wit': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'tea': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'ceremoni': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'kyoto': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'rhythm': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'latin': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'america': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'leav': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'indel': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'mark': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'intricaci': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'common': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'thread': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'growth': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'step': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'comfort': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'zone': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'navig': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'bazaar': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'conquer': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'mountain': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'peak': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'maze': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'foreign': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'resili': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'stem': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'souvenir': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'accompani': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'long': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'end': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'natur': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'masterpiec': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'wonder': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'grandeur': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'firsthand': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'aweinspir': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'majesti': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'niagara': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'fall': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'swiss': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'alp': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'teacher': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'inspir': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'awe': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'rever': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'offer': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'chanc': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'reconnect': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'earth': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'sens': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'friendship': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'way': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'forg': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'fellow': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'wander': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'stori': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'hostel': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'room': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'trek': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'strike': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'bond': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'border': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'cultiv': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'road': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'global': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'kinship': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'selfdiscoveri': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'physic': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'inner': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'provid': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'moment': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'solitud': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'reassess': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'rediscov': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'quiet': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'sunris': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'beach': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'contempl': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'ancient': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'ruin': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'still': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'summital': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'introspect': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'creed': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'storytel': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'shape': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'narr': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'curios': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'open': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'willing': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'acknowledg': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'short': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'weekend': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'getaway': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'monthslong': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'expedit': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'everevolv': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'live': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'profound': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'move': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'weav': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'travers': {'file2.txt', 'travel2299.txt', 'voyage.txt', 'voyager1.txt'},\n",
       " 'journeyon': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'mind': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'remind': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'wondrou': {'file2.txt', 'travel2299.txt', 'voyager1.txt'},\n",
       " 'evolut': {'voyage.txt'},\n",
       " '21st': {'voyage.txt'},\n",
       " 'dynam': {'voyage.txt'},\n",
       " 'evolv': {'voyage.txt'},\n",
       " 'technolog': {'voyage.txt'},\n",
       " 'advanc': {'voyage.txt'},\n",
       " 'grow': {'voyage.txt'},\n",
       " 'appetit': {'voyage.txt'},\n",
       " 'notion': {'voyage.txt'},\n",
       " 'simpl': {'voyage.txt'},\n",
       " 'individu': {'voyage.txt'},\n",
       " 'paint': {'voyage.txt'},\n",
       " 'hue': {'voyage.txt'},\n",
       " 'notabl': {'voyage.txt'},\n",
       " 'shift': {'voyage.txt'},\n",
       " 'contemporari': {'voyage.txt'},\n",
       " 'access': {'voyage.txt'},\n",
       " 'rise': {'voyage.txt'},\n",
       " 'budget': {'voyage.txt'},\n",
       " 'airlin': {'voyage.txt'},\n",
       " 'onlin': {'voyage.txt'},\n",
       " 'agenc': {'voyage.txt'},\n",
       " 'economi': {'voyage.txt'},\n",
       " 'platform': {'voyage.txt'},\n",
       " 'ever': {'voyage.txt'},\n",
       " 'longer': {'voyage.txt'},\n",
       " 'confin': {'voyage.txt'},\n",
       " 'elit': {'voyage.txt'},\n",
       " 'democrat': {'voyage.txt'},\n",
       " 'pursuit': {'voyage.txt'},\n",
       " 'contin': {'voyage.txt'},\n",
       " 'pivot': {'voyage.txt'},\n",
       " 'role': {'voyage.txt'},\n",
       " 'smartphon': {'voyage.txt'},\n",
       " 'indispens': {'voyage.txt'},\n",
       " 'companion': {'voyage.txt'},\n",
       " 'realtim': {'voyage.txt'},\n",
       " 'translat': {'voyage.txt'},\n",
       " 'instant': {'voyage.txt'},\n",
       " 'recommend': {'voyage.txt'},\n",
       " 'social': {'voyage.txt'},\n",
       " 'serv': {'voyage.txt'},\n",
       " 'digit': {'voyage.txt'},\n",
       " 'diari': {'voyage.txt'},\n",
       " 'escapad': {'voyage.txt'},\n",
       " 'audienc': {'voyage.txt'},\n",
       " 'moreov': {'voyage.txt'},\n",
       " 'experienti': {'voyage.txt'},\n",
       " 'redefin': {'voyage.txt'},\n",
       " 'seek': {'voyage.txt'},\n",
       " 'sightse': {'voyage.txt'},\n",
       " 'yearn': {'voyage.txt'},\n",
       " 'authent': {'voyage.txt'},\n",
       " 'encount': {'voyage.txt'},\n",
       " 'engag': {'voyage.txt'},\n",
       " 'delv': {'voyage.txt'},\n",
       " 'rich': {'voyage.txt'},\n",
       " 'homestay': {'voyage.txt'},\n",
       " 'activ': {'voyage.txt'},\n",
       " 'genuin': {'voyage.txt'},\n",
       " 'spontan': {'voyage.txt'},\n",
       " 'trip': {'voyage.txt'},\n",
       " 'driven': {'voyage.txt'},\n",
       " 'desir': {'voyage.txt'},\n",
       " 'frequent': {'voyage.txt'},\n",
       " 'meaning': {'voyage.txt'},\n",
       " 'escap': {'voyage.txt'},\n",
       " 'citi': {'voyage.txt'},\n",
       " 'break': {'voyage.txt'},\n",
       " 'microadventur': {'voyage.txt'},\n",
       " 'popular': {'voyage.txt'},\n",
       " 'choic': {'voyage.txt'},\n",
       " 'rejuven': {'voyage.txt'},\n",
       " 'need': {'voyage.txt'},\n",
       " 'extend': {'voyage.txt'},\n",
       " 'multifacet': {'voyage.txt'},\n",
       " 'woven': {'voyage.txt'},\n",
       " 'distant': {'voyage.txt'},\n",
       " 'dream': {'voyage.txt'},\n",
       " 'mani': {'voyage.txt'},\n",
       " 'encourag': {'voyage.txt'},\n",
       " 'ventur': {'voyage.txt'},\n",
       " 'everchang': {'voyage.txt'},\n",
       " 'reach': {'voyage.txt'}}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_manager.inverse_index_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 results:\n",
      "modern_travel.docx\n",
      "voyager1.txt\n",
      "file2.txt\n",
      "voyage.txt\n",
      "travel2299.txt\n"
     ]
    }
   ],
   "source": [
    "def search_by_keyword():\n",
    "    keyword = input(\"Enter the keyword: \")\n",
    "    word =stemmer.stem(keyword.lower())\n",
    "    results = file_manager.search_keyword(word)\n",
    "    if len(results) == 0:\n",
    "        print(\"No results found\")\n",
    "    else:\n",
    "        print(f\"Found {len(results)} results:\")\n",
    "        for result in results:\n",
    "            print(result)\n",
    "\n",
    "search_by_keyword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['modern_travel.docx', 'voyager1.txt', 'file2.txt', 'voyage.txt', 'travel2299.txt']\n",
      "Found 5 results:\n",
      "modern_travel.docx\n",
      "voyager1.txt\n",
      "file2.txt\n",
      "voyage.txt\n",
      "travel2299.txt\n"
     ]
    }
   ],
   "source": [
    "def search_by_keywords_association():\n",
    "    keywords = input(\"Enter the keywords separated by a comma: \")\n",
    "    keywords = keywords.split(\",\")\n",
    "    results = file_manager.search_keyword_association(keywords)\n",
    "    if len(results) == 0:\n",
    "        print(\"No results found\")\n",
    "    else:\n",
    "        print(f\"Found {len(results)} results:\")\n",
    "        for result in results:\n",
    "            print(result)\n",
    "\n",
    "search_by_keywords_association()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file3_554.txt',\n",
       " 'tigerwood__55.txt',\n",
       " 'modern_travel.docx',\n",
       " 'file2.txt',\n",
       " 'travel2299.txt',\n",
       " 'voyage.txt',\n",
       " 'voyager1.txt']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_in_content():\n",
    "    keyword = input(\"Enter the keyword: \")\n",
    "    results = []\n",
    "    for root, dirs, files in os.walk('docs'):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                file_content = file_manager.upload_file(file_path)\n",
    "                if keyword.lower() in file_content.lower():\n",
    "                        results.append(file_path.split(\"\\\\\")[-1])\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de la lecture du fichier {file_path}: {e}\")\n",
    "    return results\n",
    "search_in_content()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
